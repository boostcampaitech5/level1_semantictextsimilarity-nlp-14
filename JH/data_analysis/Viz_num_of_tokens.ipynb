{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## source, score별로 나누어서 토큰 개수 확인해보기 \n",
    "\n",
    "# settings\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "train_path = './data/train.csv'\n",
    "dev_path = './data/dev.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_path)\n",
    "dev_data = pd.read_csv(dev_path)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('klue/roberta-small')\n",
    "\n",
    "# Function Settings\n",
    "def get_num_tokens(df):\n",
    "    sentence1_len, sentence2_len = [], []\n",
    "    sentence1_unk, sentence2_unk = [], []\n",
    "    \n",
    "    for i, item in df.iterrows():\n",
    "        sentence1 = tokenizer(item['sentence_1'])['input_ids']\n",
    "        sentence2 = tokenizer(item['sentence_2'])['input_ids']\n",
    "\n",
    "        sentence1_len.append(len(sentence1))\n",
    "        sentence2_len.append(len(sentence2))\n",
    "\n",
    "        sentence1_unk.append(sentence1.count(tokenizer.unk_token_id))\n",
    "        sentence2_unk.append(sentence2.count(tokenizer.unk_token_id))\n",
    "\n",
    "    return sentence1_len, sentence2_len, sentence1_unk, sentence2_unk\n",
    "    # return pd.DataFrame({'number of tokens':sentence1_len, 'label score':df.label.values.tolist()})\n",
    "\n",
    "\n",
    "# 1. 전체 df에 대해 score 5단계로 분류, 열 추가\n",
    "train_data_scored = train_data.copy(deep=True)\n",
    "score_integer = []\n",
    "\n",
    "for i, item in train_data_scored.iterrows():\n",
    "    label_value = int(item['label'])\n",
    "    if   label_value == 0:  col = 0\n",
    "    elif label_value < 2.0: col = 1\n",
    "    elif label_value < 3.0: col = 2\n",
    "    elif label_value < 4.0: col = 3\n",
    "    elif label_value < 5.0: col = 4\n",
    "    else:                   col = 5\n",
    "        \n",
    "    score_integer.append(col)\n",
    "train_data_scored['score_class'] = score_integer\n",
    "\n",
    "# 2. sentence 별 토큰 개수 넣기\n",
    "s1_len, s2_len, s1_unk, s2_unk = get_num_tokens(train_data_scored)\n",
    "\n",
    "train_data_scored['s1_num_tokens'] = s1_len\n",
    "train_data_scored['s2_num_tokens'] = s2_len\n",
    "train_data_scored['s1_num_unk'] = s1_unk\n",
    "train_data_scored['s2_num_unk'] = s2_unk\n",
    "\n",
    "\n",
    "source_list = sorted(train_data['source'].unique())\n",
    "\n",
    "for source_name in source_list:\n",
    "    # 3. source 별로 그룹화 - test for nsmc\n",
    "    grouped_df = train_data_scored.groupby(['source'])\n",
    "    grouped_df = grouped_df.get_group(source_name).groupby(['score_class'])\n",
    "\n",
    "    # score 0~5\n",
    "    score_list_unique = sorted(list(set(score_integer)))\n",
    "\n",
    "    # 3-1. axis setting. x=토큰개수, y=해당 개수\n",
    "    x_axis, y_axis = [], []\n",
    "    fig, axes = plt.subplots(6, 1, \n",
    "                             figsize=(13, 7), \n",
    "                             sharey=True, \n",
    "                             sharex=True\n",
    "                             )\n",
    "    \n",
    "    # max y variable\n",
    "    # _max_y_value = -1\n",
    "\n",
    "    # 3-1. score 0~5 별로 그룹핑\n",
    "    for score in score_list_unique:\n",
    "        s1_x, s1_y, s2_x, s2_y = [], [], [], []\n",
    "        u1_x, u1_y, u2_x, u2_y = [], [], [], []\n",
    "        grouped_df_scored = grouped_df.get_group(score).copy(deep=True)\n",
    "        \n",
    "        s1_counted   = OrderedDict(Counter(sorted(grouped_df_scored['s1_num_tokens'].values.tolist())))\n",
    "        s2_counted   = OrderedDict(Counter(sorted(grouped_df_scored['s2_num_tokens'].values.tolist())))\n",
    "        unk1_counted = OrderedDict(Counter(sorted(grouped_df_scored['s1_num_unk'].values.tolist())))\n",
    "        unk2_counted = OrderedDict(Counter(sorted(grouped_df_scored['s2_num_unk'].values.tolist())))\n",
    "        \n",
    "        s1_x, s1_y = s1_counted.keys(),   s1_counted.values()\n",
    "        s2_x, s2_y = s2_counted.keys(),   s2_counted.values()\n",
    "        u1_x, u1_y = unk1_counted.keys(), unk1_counted.values()\n",
    "        u2_x, u2_y = unk2_counted.keys(), unk2_counted.values()\n",
    "        \n",
    "        axes[score].bar(s1_x, s1_y, color='royalblue')\n",
    "        axes[score].grid(zorder=0)\n",
    "        #axes[score].bar(u1_x, list(u1_y), bottom=list(s1_y), color='tomato')\n",
    "\n",
    "        for idx, value in zip(s1_x, s1_y):\n",
    "            if idx % 10 != 0 and score != 5:\n",
    "                continue\n",
    "            \n",
    "            axes[score].text(idx, value+5, s=value, ha='center', fontsize='x-small', fontweight='bold')\n",
    "            \n",
    "        #axes[score].set_ylim(0, 150)\n",
    "    \n",
    "    fig.suptitle(f\"Number of Tokens in {source_name} (only for sentence 1)\", fontsize=16, fontweight='bold')\n",
    "    #axes.set_xlabel('number of tokens', fontsize=12)\n",
    "    #axes.set_ylabel('number of each size of sentences', fontsize=12)\n",
    "    \n",
    "    \n",
    "    fig.text(0.5, 0.04, 'Common X Label', ha='center', fontsize=12, fontweight='bold')\n",
    "    fig.text(0.08, 0.5, 'number of each size of sentences', va='center', rotation='vertical', fontsize=12, fontweight='bold')\n",
    "\n",
    "    #axes[5].set_ylim(0, 5)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
