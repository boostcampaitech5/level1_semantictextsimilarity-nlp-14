{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "9324it [00:26, 354.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>sentence_1</th>\n",
       "      <th>sentence_2</th>\n",
       "      <th>label</th>\n",
       "      <th>binary-label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>boostcamp-sts-v1-train-000</td>\n",
       "      <td>nsmc-sampled</td>\n",
       "      <td>스릴도있고 반전도 있고 여느 한국영화 쓰레기들하고는 차원이 다르네요~</td>\n",
       "      <td>반전도 있고,사랑도 있고재미도있네요.</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boostcamp-sts-v1-train-001</td>\n",
       "      <td>slack-rtt</td>\n",
       "      <td>앗 제가 접근 권한이 없다고 뜹니다;;</td>\n",
       "      <td>오, 액세스 권한이 없다고 합니다.</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boostcamp-sts-v1-train-002</td>\n",
       "      <td>petition-sampled</td>\n",
       "      <td>주택청약조건 변경해주세요.</td>\n",
       "      <td>주택청약 무주택기준 변경해주세요.</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boostcamp-sts-v1-train-003</td>\n",
       "      <td>slack-sampled</td>\n",
       "      <td>입사후 처음 대면으로 만나 반가웠습니다.</td>\n",
       "      <td>화상으로만 보다가 리얼로 만나니 정말 반가웠습니다.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>boostcamp-sts-v1-train-004</td>\n",
       "      <td>slack-sampled</td>\n",
       "      <td>뿌듯뿌듯 하네요!!</td>\n",
       "      <td>꼬옥 실제로 한번 뵈어요 뿌뿌뿌~!~!</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           id            source  \\\n",
       "0  boostcamp-sts-v1-train-000      nsmc-sampled   \n",
       "1  boostcamp-sts-v1-train-001         slack-rtt   \n",
       "2  boostcamp-sts-v1-train-002  petition-sampled   \n",
       "3  boostcamp-sts-v1-train-003     slack-sampled   \n",
       "4  boostcamp-sts-v1-train-004     slack-sampled   \n",
       "\n",
       "                               sentence_1                    sentence_2  \\\n",
       "0  스릴도있고 반전도 있고 여느 한국영화 쓰레기들하고는 차원이 다르네요~          반전도 있고,사랑도 있고재미도있네요.   \n",
       "1                   앗 제가 접근 권한이 없다고 뜹니다;;           오, 액세스 권한이 없다고 합니다.   \n",
       "2                          주택청약조건 변경해주세요.            주택청약 무주택기준 변경해주세요.   \n",
       "3                  입사후 처음 대면으로 만나 반가웠습니다.  화상으로만 보다가 리얼로 만나니 정말 반가웠습니다.   \n",
       "4                              뿌듯뿌듯 하네요!!         꼬옥 실제로 한번 뵈어요 뿌뿌뿌~!~!   \n",
       "\n",
       "   label  binary-label  \n",
       "0    2.2           0.0  \n",
       "1    4.2           1.0  \n",
       "2    2.4           0.0  \n",
       "3    3.0           1.0  \n",
       "4    0.0           0.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기존 데이터세트에서 UNK로 인식되는 경우에는 스펠링 체크한 것으로 변경해주는 것이 우선이다(0417)\n",
    "# 기존 데이터세트 UNK, 스펠링 체크진행\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "sys.path.append('./py-hanspell')\n",
    "from tqdm import tqdm\n",
    "from hanspell import spell_checker\n",
    "\n",
    "\n",
    "train_path = './data/train.csv'\n",
    "dev_path = './data/dev.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_path)\n",
    "dev_data = pd.read_csv(dev_path)\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('klue/roberta-small')\n",
    "\n",
    "train_data = pd.read_csv(train_path)\n",
    "train_data_unk_corrected = train_data.copy(deep=True)\n",
    "\n",
    "for i, item in tqdm(train_data.iterrows()):\n",
    "    sentence_1, sentence_2 = item['sentence_1'], item['sentence_2']\n",
    "    unk1_tokens, unk2_tokens = [], []\n",
    "    \n",
    "    # 1-1. UNK check - sentene 1\n",
    "    encode_1, encode_2 = tokenizer(sentence_1), tokenizer(sentence_2)\n",
    "    if encode_1['input_ids'].count(tokenizer.unk_token_id):\n",
    "        unk_tok_1 = []\n",
    "        \n",
    "        decode_1 = tokenizer.convert_ids_to_tokens(encode_1['input_ids'])\n",
    "        unk_idx = [i for i, token in enumerate(decode_1) if token == tokenizer.unk_token]\n",
    "        \n",
    "        for _idx in unk_idx:\n",
    "            char_index = encode_1.token_to_chars(_idx)\n",
    "            original_token = sentence_1[char_index.start:char_index.end]  # char_index 는 CharSpan(start=15, end=19) 형태로 리턴되더랍니다... 신기!\n",
    "            \n",
    "            unk_tok_1.append(original_token)\n",
    "        \n",
    "        if unk_tok_1:\n",
    "            unk1_tokens.append(unk_tok_1)\n",
    "            \n",
    "        # 2. spelling correction\n",
    "        result_1 = spell_checker.check(sentence_1).as_dict()\n",
    "        checked_1 = result_1['checked']\n",
    "        \n",
    "        if checked_1 != sentence_1:      # 하나라도 스펠링 바뀌면 바꾼 것으로 대체해서 넣는다.\n",
    "            train_data_unk_corrected.loc[i, 'sentence_1'] = checked_1\n",
    "        \n",
    "    \n",
    "    # 1-2. UNK check - sentene 2\n",
    "    if encode_2['input_ids'].count(tokenizer.unk_token_id):\n",
    "        unk_tok_2 = []\n",
    "        \n",
    "        decode_2 = tokenizer.convert_ids_to_tokens(encode_2['input_ids'])\n",
    "        unk_idx = [i for i, token in enumerate(decode_2) if token == tokenizer.unk_token]\n",
    "        \n",
    "        for _idx in unk_idx:\n",
    "            char_index = encode_2.token_to_chars(_idx)\n",
    "            original_token = sentence_2[char_index.start:char_index.end]  # char_index 는 CharSpan(start=15, end=19) 형태로 리턴되더랍니다... 신기!\n",
    "            \n",
    "            unk_tok_2.append(original_token)\n",
    "        \n",
    "        if unk_tok_2:\n",
    "            unk2_tokens.append(unk_tok_2)\n",
    "            \n",
    "        # 2. spelling correction\n",
    "        result_2 = spell_checker.check(sentence_2).as_dict()\n",
    "        checked_2 = result_2['checked']\n",
    "        \n",
    "        if checked_2 != sentence_2:      # 하나라도 스펠링 바뀌면 바꾼 것으로 대체해서 넣는다.\n",
    "            train_data_unk_corrected.loc[i, 'sentence_2'] = checked_2\n",
    "    \n",
    "train_data_unk_corrected.to_csv(\"./data/train_unk_corrected.csv\")\n",
    "train_data_unk_corrected.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
