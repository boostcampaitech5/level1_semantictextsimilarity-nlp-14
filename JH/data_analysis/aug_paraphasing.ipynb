{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pororo 이용하여 일정 토큰개수 이상 text data paraphrasing 하기\n",
    "- pororo를 위한 환경세팅 참고: https://kakaobrain.github.io/pororo/notes/intro.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pororo only supports python>=3.6\n",
    "!conda create -n pororo python=3.6\n",
    "!conda activate pororo\n",
    "\n",
    "# ipykernel 설치 필요\n",
    "!pip install ipykernel\n",
    "!python -m ipykernel install --user --name <ENV_NAME> --display-name \"My Python Environment\"\n",
    "# ex: !python -m ipykernel install --user --name pororo --display-name pororo_kernel\n",
    "\n",
    "!git clone https://github.com/kakaobrain/pororo.git\n",
    "!cd pororo\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from pororo import Pororo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, OrderedDict\n",
    "\n",
    "train_path = '~/data/train_clean_correct.csv'\n",
    "dev_path = '~/data/dev_clean_correct.csv'\n",
    "\n",
    "train_data = pd.read_csv(train_path)\n",
    "dev_data = pd.read_csv(dev_path)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('klue/roberta-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmentation by paraphrasing\n",
    "\n",
    "# setting\n",
    "from pororo import Pororo\n",
    "paraphrasing = Pororo(task=\"pg\", lang=\"ko\")\n",
    "\n",
    "\n",
    "# functions\n",
    "def paraphrased(text):\n",
    "    tok = tokenizer(text)['input_ids']\n",
    "    if len(tok) >= 11:\n",
    "        paraphrased = paraphrasing(text,\n",
    "                        beam=5,\n",
    "                        len_penalty=0.7,\n",
    "                        no_repeat_ngram_size=4,\n",
    "                        top_k=50,\n",
    "                        top_p=0.7\n",
    "                        )\n",
    "        return paraphrased\n",
    "    else:\n",
    "        return\n",
    "\n",
    "def continue_condition(score, zero_count):\n",
    "    flag = True\n",
    "    \n",
    "    if score < 1.0:\n",
    "        zero_count = zero_count + 1\n",
    "        if zero_count % 33 == 0:            # 3% 만 증강\n",
    "            flag = False\n",
    "    else:\n",
    "        flag = False\n",
    "    # elif score >= 1.0 and score < 2.0:\n",
    "    #     one_count = one_count + 1\n",
    "    #     if one_count % 3 != 0:              # 66% 만 증강\n",
    "    #         flag = True\n",
    "    \n",
    "    return flag, zero_count\n",
    "\n",
    "def aug_paraphrase(df):\n",
    "    df_copied = df.copy(deep=True)\n",
    "    aug_1, aug_2, label, blabel = [], [], [], []\n",
    "    zero_count = 0\n",
    "    \n",
    "    for i, item in tqdm(df_copied.iterrows()):\n",
    "        # 1. 행 하나 읽고\n",
    "        org_1, org_2 = item['sentence_1'], item['sentence_2']\n",
    "        org_label, org_blabel = item['label'], item['binary-label']\n",
    "        \n",
    "        # 1-1. 0~1은 좀 많이 안 증가시키고 싶다. 0 이면 80\n",
    "        flag, zero_count = continue_condition(org_label, zero_count)\n",
    "        if flag:\n",
    "            continue\n",
    "        \n",
    "        # 2. org_1에 대해\n",
    "        par_1, par_2 = paraphrased(org_1), paraphrased(org_2)\n",
    "        \n",
    "        if par_1:\n",
    "            \n",
    "            # 2-1-1. (ps1, org s2) + org label\n",
    "            aug_1.append(par_1)\n",
    "            aug_2.append(org_2)\n",
    "            label.append(org_label)\n",
    "            blabel.append(org_blabel)\n",
    "            \n",
    "            # 전체 약 9300 개에서 토큰개수 11개이상(평균이 13개정도)이 12007 개. 여기서 5 라벨은 114 개. 2배 증가 + 3000개 증가\n",
    "            # 1-3-2. org1 - ps1 : 5.0으로 설정\n",
    "            if i%7 == 0 and org_label != 5.0:\n",
    "                aug_1.append(org_1)\n",
    "                aug_2.append(par_1)\n",
    "                label.append(5.0)\n",
    "                blabel.append(1.0)\n",
    "        \n",
    "        # 3. org_2에 대해\n",
    "        if par_2:\n",
    "            \n",
    "            # 3-1-1. (org s1, ps2) + org label\n",
    "            aug_1.append(org_1)\n",
    "            aug_2.append(par_2)\n",
    "            label.append(org_label)\n",
    "            blabel.append(org_blabel)\n",
    "            \n",
    "            # 3-1-2. org2 - ps2 : 5.0으로 설정.\n",
    "            if i%13 == 0 and org_label != 5.0:\n",
    "                aug_1.append(par_2)\n",
    "                aug_2.append(org_2)\n",
    "                label.append(5.0)\n",
    "                blabel.append(1.0)\n",
    "        # if i%10 == 0:\n",
    "        #     print(f\"aug1: {aug_1}\\naug2: {aug_2}\")\n",
    "        \n",
    "    # 4. DataFrame\n",
    "    _id = [\"paraphrased\"] * len(aug_1)\n",
    "    aug_df = pd.DataFrame({'id': _id,\n",
    "                        'sentence_1': aug_1,\n",
    "                        'sentence_2': aug_2,\n",
    "                        'label': label,\n",
    "                        'binary-label': blabel,\n",
    "                        })\n",
    "    concated_df = pd.concat([df_copied, aug_df])\n",
    "\n",
    "    # 5. save\n",
    "    concated_df.to_csv(\"./train_paraphrased.csv\", index=False)\n",
    "    aug_df.to_csv(\"./train_parap_onlyaug.csv\", index=False)\n",
    "    \n",
    "    return concated_df, aug_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paraphrased, train_parap_onlyaug = aug_paraphrase(train_data)\n",
    "\n",
    "train_parap_onlyaug.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_parap_onlyaug.head(5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
